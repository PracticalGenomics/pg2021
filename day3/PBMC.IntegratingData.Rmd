---
author: "Luigi Marchionni"
date: "9/25/2021"
title: "IntegratingDataOsca"
output: html_document
---

# Preliminary operations

```{r compileRMD, echo=FALSE, eval=TRUE}
### Libraries necessary for knitting
library(rmarkdown, quietly = TRUE)
```

## Load the required general libraries for typesetting

```{r setup}
### Clean the workspace
rm(list=ls())
ls()
### Load the required libraries
library(knitr, quietly = TRUE)
knitr::opts_chunk$set(echo = TRUE)
### To run and output elsewhere
knitPath <- "/home/idies/workspace/practical_genomics/day3/"
print(knitPath)
opts_knit$set(root.dir = knitPath) #tidy=TRUE, tidy.opts=list(width.cutoff=180))
```

## Set the correct working directory

```{r}
### Finding your current working directory
getwd()
### Setting the working directory (change this)
setwd(knitPath)
### Check working directory
getwd()
```

# Integrating Datasets Single cell RNA seq (scRNAseq) datasets
## Assembling data from different experiments

Large scRNA-seq projects are usually generated in multiple batches due to logistical constraints. These different batches will present systematic and inherent differences in expression levels due to technical factors (e.g., different reagents, days, instruments, etc, ...), the so called “batch effects”. These are  pervasive in all omics experiments and techniques, since they can result  in major heterogeneity in the data, offuscating biologically relevant differences.

Batch effects have been known for a long time, have been intensively "studied", and methods for their correction (or control of) have been devised for enabling downstream analyses. For "bulk" genomics, however, the existing methods assume similar or known cell population composition across batches and use linear models (Ritchie et al. 2015; Leek et al. 2012). These assumption do not apply to scRNAseq data, hence novel methods that do not require a priori knowledge on cell composition have been devised (Haghverdi et al. 2018; Butler et al. 2018; Lin et al. 2019).

### Loading the data

Now let's play around with an example: integrating two separate 10X Genomics PBMC datasets generated in two different batches. To this end, the datasets were retrieved from the `TENxPBMCData` package, and then separately processed prior to batch correction. This is more scalable and usually also more reliable (e.g., QC based on outliers and mean-variance trend fitting are more effective when performed within batches). The code used for pre-processing is contained in the file named "PBMC.prepareData.Rmd" (see inside directory "day3").

So, let's start now by loading and exploring the PBMC expression data (that we have SEPARATELY pre-processed). Note that this datasets has been "reduced" in size by randomly selecting 500 cells and 15,000 genes per study.

```{r}
### Load libraries used for pre-processing just in case
library(scater, quietly = TRUE)
library(scran, quietly = TRUE)
library(BiocSingular, quietly = TRUE)
### Load the object
load("./PBMC.sce.small.rda")
### Check class, names, modes, structure, and more
class(all.sce)
names(all.sce)
### Check individual list elements
lapply(all.sce, class)
### How many genes and cells
lapply(all.sce, dim)
```

For data integration, the first step is to find the common "universe" of genes shared across the different datasets. Here we are lucky, since the datasets are already annotated using the same system (Ensembl). If this was not not the case, ensuring the same annotation would be the first thing to do.

```{r, echo=TRUE, eval=TRUE}
### Find the shared universe of genes among datasets
universe <- intersect(rownames(all.sce$pbmc3k), rownames(all.sce$pbmc4k))
length(universe)
### Subset the datasets (in the form of 'SingleCellExperiment' objects)
pbmc3k <- all.sce$pbmc3k[universe,]
pbmc4k <- all.sce$pbmc4k[universe,]
### Also subset the variance
dec3k <- all.dec$pbmc3k[universe,]
dec4k <- all.dec$pbmc4k[universe,]
###
nrow(pbmc3k) == nrow(pbmc4k)
```

The next step is to rescale each batch to adjust for depth sequencing between batches. The is conveniently done by using the `multiBatchNorm()` function, which computes log-normalized expression values after adjusting for `SingleCellExperiment` coverage differences between datasets. This step improves data quality by removing a major technical difference between batches.

```{r}
### Load the necessary library
library(batchelor)
### Process all datasets, rescaling them by library depth
rescaled <- multiBatchNorm(pbmc3k, pbmc4k)
pbmc3k <- rescaled[[1]]
pbmc4k <- rescaled[[2]]
```

Finally, feature selection is better achieved by averaging the variance components across batches (using the `combineVar()` function from the `scran` package). This is important since this average better captures the behavior of batch-specific highly variable genes (HVGs), while preserving gene ranking within-batch. On the contrary, using the union or the intersection of HVGs between batches has different implications depending on thenumber of datasets/studies used (too conservative or liberal).

That said, it is generally safer to include more genes than usally included in the analysis of a single dataset, since we wnat to ensure that all important markers are retained for each dataset-specific sub-population, altough alternative, more conservative solutions might also be warranted.

```{r}
### Combine the datasets
combined.dec <- combineVar(dec3k, dec4k)
### Class and structure of the object
class(combined.dec)
head(combined.dec)
### How many > 0?
chosen.hvgs <- combined.dec$bio > 0
sum(chosen.hvgs)
```

### Diagnosing batch effects
Let's check if there is any batch effect in this combined dataset before trying to remove it. To this end, we first combine the two `SingleCellExperiments` and then perform a PCA using the `runPCA()` funciton on the log-expression values.

```{r}
### Synchronizing the metadata for cbind()ing.
nrow(pbmc3k) == nrow(pbmc4k)
### Are the rows in the same order?
all(rownames(pbmc3k) == rownames(pbmc4k))
### Make the rowData identical
rowData(pbmc3k) <- rowData(pbmc4k)
### Add batch value
pbmc3k$batch <- "3k"
pbmc4k$batch <- "4k"
### Bind
uncorrected <- cbind(pbmc3k, pbmc4k)
### Run PCA using the 'RandomParam()' function since this is more efficient
### for file-backed matrices. First set seed
set.seed(0010101010)
uncorrected <- runPCA(uncorrected, subset_row=chosen.hvgs,
    BSPARAM=BiocSingular::RandomParam())
### save
  save(uncorrected, file="./PBMC.sce.uncor.small.rda")
```

Here, we will perform graph-based clustering on the components summarize the cell population structure. The the PBMC datasets we are analyzing can be considered replicates, hence the populations should be the same, and each cell type cluster should account for cells from both studies (i.e., batches). If we will instead observe clusters that contains cells from single batches, we shall conclude that there is an important batch effect.

```{r}
### Build graph based clustering
snn.gr <- buildSNNGraph(uncorrected, use.dimred="PCA")
clusters <- igraph::cluster_walktrap(snn.gr)$membership
### Compile results into a table
tab <- table(Cluster=clusters, Batch=uncorrected$batch)
kable(tab)
```

Such results can also be visulalized in a T-SNE plot, coloring the batches with distinct colors. It appears evident the the large separation between cells is driven by batches.

```{r}
### Set seed
set.seed(1111001)
### Run t-SNE on the uncorrected data
uncorrected <- runTSNE(uncorrected, dimred="PCA")
### Check
uncorrected
### Plot the results
plotTSNE(uncorrected, colour_by="batch")
```

Using the degree to which cell intermingle across different batches is not ideal to diagnose batch effects (and their correction), since different batches can contain cell populations that are unique (and not present in the other batches), and which therefore will never "merge". Biological considerations, rather than statistical ones, should be used to answer this question.

## Linear regression
Linear regression is commonly used to remove batch effects in bulk RNA sequencing studies and compute corrected expression values for downstream analyses (e.g, by using  `removeBatchEffect()` function from the `limma` package or the `comBat()` function in the `sva` package). The assumption to use this approachwith scRNA-seq data is that all studies to be merged have the same cell subpopulation composition. Furthremore, it is also assumed that fold-changes due to batch effects are the same for all cell subpopulations and all genes. These assumptions might apply only for technical replicates generated from the same cell populations. This can be achieved by using the `rescaleBatches()` function from the `batchelor` package.
As an alternative, we can also use the `regressBatches()` function, which is based on a more conventional linear regression approach, which, however, does not take into account sparsity in the matrix of residuals (unlike `rescaleBatches()`).

```{r}
### Rescaling
rescaled <- rescaleBatches(pbmc3k, pbmc4k)
### Check the results
rescaled
```

We can now repeat clustering and verify if cells from distinct batches are now coming together.

```{r}
### To ensure reproducibility of the randomized PCA.
### Set seed
set.seed(1010101010) 
### PCA
rescaled <- runPCA(rescaled, subset_row=chosen.hvgs, 
    exprs_values="corrected",
    BSPARAM=BiocSingular::RandomParam())
### Check
rescaled
### Build graph-based cluster
snn.gr <- buildSNNGraph(rescaled, use.dimred="PCA")
clusters.resc <- igraph::cluster_walktrap(snn.gr)$membership
### Compile the results and check
tab.resc <- table(Cluster=clusters.resc, Batch=rescaled$batch)
tab.resc
```

Let's now visualize the results in a T-SNE plot

```{r}
### Set seed
set.seed(1111001)
### Run t-SNE on the corrected data
rescaled <- runTSNE(rescaled, dimred="PCA")
rescaled$batch <- factor(rescaled$batch)
### Plot the results
plotTSNE(rescaled, colour_by="batch")
```

## Performing MNN correction
Another approach to batch correction is based on 'mutual nearest neighbors" (MMN, see Haghverdi et al, Nat Biotech, 2018). With this approach any given cell in one batch is compared to the set of neighbor cells from the other batch, and vice-versa. Assuming that cells in within MNNs represent cells from the same population and in the same state, the differences between them are used to estimate the batch effect correction.

An advantage of this approach is that, unlike linear regression, there are no assumptions about the cell populations, which can be different between batches. This is possible since the population structure is obtained from the data through the identification of MNNs. The underlying assumption is that batch effects are not orthogonal with biological differences between clusters.

The `fastMNN()` function from the `batchelor` package implements an MNN approach that uses PCA to reduce the dimensions and speed up the detection. The most relevant parameter for tuning `fastMNN()` is `k`, which specifies the number of nearest neighbors to consider when defining MNN pairs. Increasing `k` will result in more aggressive corrections.

Please note that this functions returns a `SingleCellExperiment` object containing the corrected values to be used in downstream analyses. Cells are stored by column, genes are represented by distinct rows, while original batch information is stored in the object metadata. The matrix returned by `reducedDims()` contains the low-dimensional corrected coordinates for all cells. Finally, the  `assays()` slots contains the corrected expression values for each gene in each cell (note that these values should be only used for visualization).

```{r}
### Set the seed
set.seed(1000101001)
### Use 'fatMNN' with some specific options forr greater speed.
mnn.out <- fastMNN(pbmc3k, pbmc4k, d=50, k=20, subset.row=chosen.hvgs,
    BSPARAM=BiocSingular::RandomParam(deferred=TRUE))
### Check the results
mnn.out
### Chaeck out bactchs
table(mnn.out$batch)
### The reduced dimension slot
dim(reducedDim(mnn.out, "corrected"))
### The corrected values
assay(mnn.out, "reconstructed")
```

We can now perform clustering and assess wether batch effect were successfully removed.

```{r}
### Build graph-bassed clusters
snn.gr <- buildSNNGraph(mnn.out, use.dimred="corrected")
clusters.mnn <- igraph::cluster_walktrap(snn.gr)$membership
### Check the results
tab.mnn <- table(Cluster=clusters.mnn, Batch=mnn.out$batch)
tab.mnn
```

### Correction diagnostics

A Pearson’s chi-squared test can be used to test whether clusters show imbalances in the contribution from the starting batches (see, Büttner et al. Nat. Biotechnol, 2019). Hence, this approach can be used to quantify the degree of mixing across batches, especially in the case of technocal replicates, when the biological variability is expected to be low.

```{r}
### Compute chi squared test and get the results
chi.prop <- colSums(tab.mnn)/sum(tab.mnn)
chi.results <- apply(tab.mnn, 1, FUN=chisq.test, p=chi.prop)
p.values <- vapply(chi.results, "[[", i="p.value", 0)
p.values
```

Another approach for assessing batch correction 'quality' is based on the variability of the clusters in terms of proportional batch abundances, where clusters that show higher variability may indicate incomplete correction. This however, cannot discriminate when the variability derives from batch-specific populations, and prior biological knowledge is required for a correct intrpretation.

```{r}
#### The following is for better manipulation of the values stored in the 'table' object
tab.mnn <- unclass(tab.mnn)
### We will focus on large pseudo.count to avoid large variances (when counts are low).
norm <- normalizeCounts(tab.mnn, pseudo.count=10)
### Now we will rank the clusters by variance
rv <- rowVars(norm)
### Let's check the results
DataFrame(Batch=tab.mnn, var=rv)[order(rv, decreasing=TRUE),]
```

Finally, a useful diagnostic is the proportion of within-batch variance lost during MNN correction. Large proportions of lost variance (>10%) suggest that correction might be removing biological heterogeneity. This information is stored in the output from `fastMNN()`.

```{r}
### Extract the lost variance infomration: not big as it appears
metadata(mnn.out)$merge.info$lost.var
```

We can now visualize the corrected coordinates using a t-SNE plot.

```{r}
### Set seed
set.seed(0010101010)
### Run t-SNE
mnn.out <- runTSNE(mnn.out, dimred="corrected")
### Add batch infomration
mnn.out$batch <- factor(mnn.out$batch)
### Plot
plotTSNE(mnn.out, colour_by="batch")
```

```{r}
### Save objects just in case
save(rescaled, mnn.out, file="./PBMC.sce.cor.small.rda")
```

## Using the corrected values
The overarching question, once the datasets are merged, is: can we use the merged data for Differential Expression (DE) analysis? Can we go beyond cluster them together and explore the cell population structure?

The answer is, well, NO.

Through batch correction, we could introduce biases between cell population we are comparing, creating artificial differences that are not there. For this reason, it is important to stick to practices that enable to control such biases. For instance, when comparing differential expression analysis, using uncorrected values is preferable to use corrected ones. This will prevent to find differences between clusters of cells because differences between batches are not necessarily aligning with cell population structures in the batches (e.g., there are biological differences of interest 'confounded' with the batches: donor effect, etc).

One solution is to perform DE analyses on the uncorrected expression values, controlling batch differences with blocking. This practice is also used (and preferable) in standard bulk RNA-seq and microarray analyses everytime the batch are known. After all, when one knows that a piece of land is mostly in the shade, or gets much less water becasuse it is on the top of the hill, one would most definitely wants to take this information into account when making any kind of inference on the yield of crops  planted in the diffenret parcels (blocks) of land...

Here this is done by using a blocked t-test to detect markers in the PBMC dataset, penalizing genes that exhibit inconsistent DE across batches.

```{r}
### Find DE markers, please note this is done using the uncorrected values and a block for the batches
m.out <- findMarkers(uncorrected, clusters.mnn, block=uncorrected$batch,
    direction="up", lfc=1, row.data=rowData(uncorrected)[,3,drop=FALSE])
### Let's look at the results
class(m.out)
names(m.out)
### We have top markers for each cluster, lets look at cluster "10"
### Is this an activated T cell subtype of some sort?
### CD3, JUN, etc...
demo <- m.out[["3"]]
kable(as.data.frame(demo[1:20,c("Symbol", "Top", "p.value", "FDR")]) )
### We can also plot expressions for selected markers (using rownames)
### Here is "CD3D", which is "ENSG00000167286", see table above
plotExpression(uncorrected, x=I(factor(clusters.mnn)), 
    features="ENSG00000167286", colour_by="batch") + facet_wrap(~colour_by)
```

In conclusion, it best to limit batch-corrected expression values for visualization (e.g., for coloring points in a t-SNE plot, etc). The use of corrected values for DE analysis, or any other kind of quantitative inference, is risky, and should be supported by results from the analyses of the uncorrected data.

# Session information
```{r}
sessionInfo()
```






